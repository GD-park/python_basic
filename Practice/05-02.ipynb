{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 7 9\n"
     ]
    }
   ],
   "source": [
    "class OrderedList(object):\n",
    "    def __init__(self):\n",
    "        self.nums = []\n",
    "        \n",
    "    def append(self, num):\n",
    "        if len(self.nums) == 0:\n",
    "            self.nums.append(num)\n",
    "        else:\n",
    "            i = 0\n",
    "            while i < len(self.nums):\n",
    "                if self.nums[i] > num:\n",
    "                    break\n",
    "                i += 1\n",
    "                \n",
    "            self.nums.insert(i, num)\n",
    "        \n",
    "    def show(self):\n",
    "        for num in self.nums:\n",
    "            print num,\n",
    "        \n",
    "    def find(self, num):\n",
    "        return num in self.nums\n",
    "    \n",
    "    \n",
    "ordered_list = OrderedList()\n",
    "ordered_list.append(9)\n",
    "ordered_list.append(4)\n",
    "ordered_list.append(3)\n",
    "ordered_list.append(2)\n",
    "ordered_list.append(7)\n",
    "ordered_list.append(1)\n",
    "ordered_list.append(5)\n",
    "\n",
    "ordered_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TFIDFCaculator(object):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.tf_dict = {}\n",
    "        self.df_dict = defaultdict(int)\n",
    "\n",
    "    def build_tf_dict(self):\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for f in files:\n",
    "                self.tf_dict[f] = defaultdict(int)\n",
    "                with open(os.path.join(self.path, f), 'r') as fout:\n",
    "                    data = fout.read()\n",
    "                    words = [word.lower() for word in data.split()] \n",
    "\n",
    "                    for w in words:\n",
    "                        self.tf_dict[f][w] += 1\n",
    "                        \n",
    "    def build_df_dict(self):\n",
    "        all_keys = list(set([key for doc in self.tf_dict for key in self.tf_dict[doc]]))\n",
    "        for key in all_keys:\n",
    "            for root, dirs, files in os.walk(self.path):\n",
    "                for f in files:\n",
    "                    with open(os.path.join(self.path, f)) as fout:\n",
    "                        data = fout.read()\n",
    "                        words = [word.lower() for word in data.split()]  \n",
    "                        if key in words:\n",
    "                            self.df_dict[key] += 1\n",
    "                            \n",
    "    def get_tf_idf_dict(self, reverse = True):\n",
    "        tf_idf_dict = {}\n",
    "        \n",
    "        for doc in self.tf_dict:\n",
    "            tf_idf_dict[doc] = {}\n",
    "            for key, value in self.tf_dict[doc].items():\n",
    "                tf_idf_dict[doc][key] = float(value) / self.df_dict[key]\n",
    "        \n",
    "        for doc in tf_idf_dict:\n",
    "            tf_idf_dict_by_doc = tf_idf_dict[doc]\n",
    "            tf_idf_dict_by_doc = OrderedDict(sorted(tf_idf_dict_by_doc.items(), key = lambda x : x[1], reverse = reverse))\n",
    "            tf_idf_dict[doc] = tf_idf_dict_by_doc\n",
    "        return tf_idf_dict\n",
    "            \n",
    "            \n",
    "path = os.getcwd() + '/data_set'            \n",
    "tf_idf = TFIDFCaculator(path)            \n",
    "\n",
    "tf_idf.build_tf_dict()\n",
    "tf_idf.build_df_dict()\n",
    "\n",
    "#print tf_idf.df_dict\n",
    "\n",
    "for doc, tf_idf_dict in tf_idf.get_tf_idf_dict().items():\n",
    "    print doc \n",
    "    print tf_idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdef\n",
      "\n",
      "abcdef\\n\n"
     ]
    }
   ],
   "source": [
    "a = 'abcdef\\n'\n",
    "print a\n",
    "\n",
    "# raw string\n",
    "b = r'abcdef\\n'\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object at 0x03BBC608>\n",
      "iii\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "match = re.search(r'iii', 'piiig')\n",
    "print match\n",
    "print match.group()\n",
    "\n",
    "match = re.search(r'iiiig', 'piiig')\n",
    "print match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iig\n",
      "123\n",
      "123\n",
      "abc\n",
      "ab0\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r'..g', 'piiig')\n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\d\\d\\d', 'p123g') \n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\d\\d\\d', '오마이갓123이럴수가') \n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\w\\w\\w', '@@abcd!!')\n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\w\\w\\w', '@@ab0!!')\n",
    "print m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macmath22@gmail.com <type 'str'>\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r'[\\w.-]+@[\\w.-]+',\n",
    "              \"My email is macmath22@gmail.com\")\n",
    "\n",
    "print m.group(), type(m.group())\n",
    "print m.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file c:\\python27\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-35bd4a4f465a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mnews1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_news_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://media.daum.net/foreign/newsview?newsid=20160921114543616'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mnews2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_news_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://media.daum.net/digital/newsview?newsid=20160920180606199'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-35bd4a4f465a>\u001b[0m in \u001b[0;36mget_news_content\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_news_content(url):\n",
    "    response = requests.get(url)\n",
    "    content = response.text\n",
    "\n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    div = soup.find('div', attrs = {'id' : 'dmcfContents'})\n",
    "    \n",
    "    content = ''\n",
    "    for paragraph in div.find_all('p'):\n",
    "        content += paragraph.get_text()\n",
    "        \n",
    "    return content.encode('utf-8')\n",
    "        \n",
    "news1 = get_news_content('http://media.daum.net/foreign/newsview?newsid=20160921114543616')\n",
    "news2 = get_news_content('http://media.daum.net/digital/newsview?newsid=20160920180606199')\n",
    "\n",
    "\n",
    "pattern = r'([\\w.-]+)@([\\w.-]+)'\n",
    "print re.search(pattern, news1).group()\n",
    "print re.search(pattern, news2).group()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

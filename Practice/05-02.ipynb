{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 7 9\n"
     ]
    }
   ],
   "source": [
    "class OrderedList(object):\n",
    "    def __init__(self):\n",
    "        self.nums = []\n",
    "        \n",
    "    def append(self, num):\n",
    "        if len(self.nums) == 0:\n",
    "            self.nums.append(num)\n",
    "        else:\n",
    "            i = 0\n",
    "            while i < len(self.nums):\n",
    "                if self.nums[i] > num:\n",
    "                    break\n",
    "                i += 1\n",
    "                \n",
    "            self.nums.insert(i, num)\n",
    "        \n",
    "    def show(self):\n",
    "        for num in self.nums:\n",
    "            print num,\n",
    "        \n",
    "    def find(self, num):\n",
    "        return num in self.nums\n",
    "    \n",
    "    \n",
    "ordered_list = OrderedList()\n",
    "ordered_list.append(9)\n",
    "ordered_list.append(4)\n",
    "ordered_list.append(3)\n",
    "ordered_list.append(2)\n",
    "ordered_list.append(7)\n",
    "ordered_list.append(1)\n",
    "ordered_list.append(5)\n",
    "\n",
    "ordered_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TFIDFCaculator(object):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.tf_dict = {}\n",
    "        self.df_dict = defaultdict(int)\n",
    "\n",
    "    def build_tf_dict(self):\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for f in files:\n",
    "                self.tf_dict[f] = defaultdict(int)\n",
    "                with open(os.path.join(self.path, f), 'r') as fout:\n",
    "                    data = fout.read()\n",
    "                    words = [word.lower() for word in data.split()] \n",
    "\n",
    "                    for w in words:\n",
    "                        self.tf_dict[f][w] += 1\n",
    "                        \n",
    "    def build_df_dict(self):\n",
    "        all_keys = list(set([key for doc in self.tf_dict for key in self.tf_dict[doc]]))\n",
    "        for key in all_keys:\n",
    "            for root, dirs, files in os.walk(self.path):\n",
    "                for f in files:\n",
    "                    with open(os.path.join(self.path, f)) as fout:\n",
    "                        data = fout.read()\n",
    "                        words = [word.lower() for word in data.split()]  \n",
    "                        if key in words:\n",
    "                            self.df_dict[key] += 1\n",
    "                            \n",
    "    def get_tf_idf_dict(self, reverse = True):\n",
    "        tf_idf_dict = {}\n",
    "        \n",
    "        for doc in self.tf_dict:\n",
    "            tf_idf_dict[doc] = {}\n",
    "            for key, value in self.tf_dict[doc].items():\n",
    "                tf_idf_dict[doc][key] = float(value) / self.df_dict[key]\n",
    "        \n",
    "        for doc in tf_idf_dict:\n",
    "            tf_idf_dict_by_doc = tf_idf_dict[doc]\n",
    "            tf_idf_dict_by_doc = OrderedDict(sorted(tf_idf_dict_by_doc.items(), key = lambda x : x[1], reverse = reverse))\n",
    "            tf_idf_dict[doc] = tf_idf_dict_by_doc\n",
    "        return tf_idf_dict\n",
    "            \n",
    "            \n",
    "path = os.getcwd() + '/data_set'            \n",
    "tf_idf = TFIDFCaculator(path)            \n",
    "\n",
    "tf_idf.build_tf_dict()\n",
    "tf_idf.build_df_dict()\n",
    "\n",
    "#print tf_idf.df_dict\n",
    "\n",
    "for doc, tf_idf_dict in tf_idf.get_tf_idf_dict().items():\n",
    "    print doc \n",
    "    print tf_idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdef\n",
      "\n",
      "abcdef\\n\n"
     ]
    }
   ],
   "source": [
    "a = 'abcdef\\n'\n",
    "print a\n",
    "\n",
    "# raw string\n",
    "b = r'abcdef\\n'\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object at 0x03BBC608>\n",
      "iii\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "match = re.search(r'iii', 'piiig')\n",
    "print match\n",
    "print match.group()\n",
    "\n",
    "match = re.search(r'iiiig', 'piiig')\n",
    "print match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iig\n",
      "123\n",
      "123\n",
      "abc\n",
      "ab0\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r'..g', 'piiig')\n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\d\\d\\d', 'p123g') \n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\d\\d\\d', '오마이갓123이럴수가') \n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\w\\w\\w', '@@abcd!!')\n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\w\\w\\w', '@@ab0!!')\n",
    "print m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macmath22@gmail.com <type 'str'>\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r'[\\w.-]+@[\\w.-]+',\n",
    "              \"My email is macmath22@gmail.com\")\n",
    "\n",
    "print m.group(), type(m.group())\n",
    "print m.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010-3457-6360\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^0\\d{2}-\\d{3,4}-\\d{4}'\n",
    "m = re.search(pattern, '010-3457-6360')\n",
    "print m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "a_bdd\n",
      "good344\n",
      "aB_23\n"
     ]
    }
   ],
   "source": [
    "variables = ['abc', '3dbd', 'a_bdd', 'good344', 'aB_23']\n",
    "\n",
    "for v in variables:\n",
    "    m = re.search(r'^[a-zA-Z_]+[\\w\\d]*', v)\n",
    "    if m != None:\n",
    "        print m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a nice weather test, test test\n"
     ]
    }
   ],
   "source": [
    "str = 'What a nice weather macmath22@gmail.com, test@test.com mina@minas.net'\n",
    "replaced = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', r'test', str) \n",
    "print replaced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdef\n",
      "\n",
      "abcdef\\n\n"
     ]
    }
   ],
   "source": [
    "a = 'abcdef\\n'\n",
    "print a\n",
    "\n",
    "# raw string\n",
    "b = r'abcdef\\n'\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object at 0x03859480>\n",
      "iii\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 첫번째꺼 찾으면 멈춤\n",
    "import re\n",
    "\n",
    "match = re.search(r'iii', 'piiig')\n",
    "print match\n",
    "print match.group()\n",
    "\n",
    "match = re.search(r'iiiig', 'piiig')\n",
    "print match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iig\n",
      "123\n",
      "123\n",
      "abc\n",
      "ab0\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r'..g', 'piiig')\n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\d\\d\\d', 'p123g') \n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\d\\d\\d', '오마이갓123이럴수가') \n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\w\\w\\w', '@@abcd!!')\n",
    "print m.group()\n",
    "\n",
    "m = re.search(r'\\w\\w\\w', '@@ab0!!')\n",
    "print m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jiyong5411@gmail.com <type 'str'>\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r'[\\w.-]+@[\\w.-]+',\n",
    "              \"My email is jiyong5411@gmail.com\")\n",
    "\n",
    "print m.group(), type(m.group())\n",
    "print m.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jiyong5411@gmail.com\n",
      "\n",
      "('jiyong5411', 'gmail.com')\n",
      "jiyong5411\n",
      "gmail.com\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r'([\\w.-]+)@([\\w.-]+)',\n",
    "              \"My email is jiyong5411@gmail.com\")\n",
    "\n",
    "print m.group()\n",
    "print ''\n",
    "print m.groups()\n",
    "\n",
    "print m.group(1)\n",
    "print m.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file c:\\python27\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-35bd4a4f465a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mnews1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_news_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://media.daum.net/foreign/newsview?newsid=20160921114543616'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mnews2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_news_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://media.daum.net/digital/newsview?newsid=20160920180606199'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-35bd4a4f465a>\u001b[0m in \u001b[0;36mget_news_content\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_news_content(url):\n",
    "    response = requests.get(url)\n",
    "    content = response.text\n",
    "\n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    div = soup.find('div', attrs = {'id' : 'dmcfContents'})\n",
    "    \n",
    "    content = ''\n",
    "    for paragraph in div.find_all('p'):\n",
    "        content += paragraph.get_text()\n",
    "        \n",
    "    return content.encode('utf-8')\n",
    "        \n",
    "news1 = get_news_content('http://media.daum.net/foreign/newsview?newsid=20160921114543616')\n",
    "news2 = get_news_content('http://media.daum.net/digital/newsview?newsid=20160920180606199')\n",
    "\n",
    "\n",
    "pattern = r'([\\w.-]+)@([\\w.-]+)'\n",
    "print re.search(pattern, news1).group()\n",
    "print re.search(pattern, news2).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

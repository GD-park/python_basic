{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TFIDFCaculator(object):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.tf_dict = {}\n",
    "        self.df_dict = defaultdict(int)\n",
    "\n",
    "    def build_tf_dict(self):\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for f in files:\n",
    "                self.tf_dict[f] = defaultdict(int)\n",
    "                with open(os.path.join(self.path, f), 'r') as fout:\n",
    "                    data = fout.read()\n",
    "                    words = [word.lower() for word in data.split()] \n",
    "\n",
    "                    for w in words:\n",
    "                        self.tf_dict[f][w] += 1\n",
    "                        \n",
    "    def build_df_dict(self):\n",
    "        all_keys = list(set([key for doc in self.tf_dict for key in self.tf_dict[doc]]))\n",
    "        for key in all_keys:\n",
    "            for root, dirs, files in os.walk(self.path):\n",
    "                for f in files:\n",
    "                    with open(os.path.join(self.path, f)) as fout:\n",
    "                        data = fout.read()\n",
    "                        words = [word.lower() for word in data.split()]  \n",
    "                        if key in words:\n",
    "                            self.df_dict[key] += 1\n",
    "                            \n",
    "    def get_tf_idf_dict(self, reverse = True):\n",
    "        #self.build_tf_dict()\n",
    "        \n",
    "        tf_idf_dict = {}\n",
    "        \n",
    "        for doc in self.tf_dict:\n",
    "            tf_idf_dict[doc] = {}\n",
    "            for key, value in self.tf_dict[doc].items():\n",
    "                tf_idf_dict[doc][key] = float(value) / self.df_dict[key]\n",
    "        \n",
    "        for doc in tf_idf_dict:\n",
    "            tf_idf_dict_by_doc = tf_idf_dict[doc]\n",
    "            tf_idf_dict_by_doc = OrderedDict(sorted(tf_idf_dict_by_doc.items(), key = lambda x : x[1], reverse = reverse))\n",
    "            tf_idf_dict[doc] = tf_idf_dict_by_doc\n",
    "        return tf_idf_dict\n",
    "            \n",
    "            \n",
    "path = os.getcwd() + '/data_set'            \n",
    "tf_idf = TFIDFCaculator(path)            \n",
    "\n",
    "tf_idf.build_tf_dict()\n",
    "tf_idf.build_df_dict()\n",
    "\n",
    "for doc, tf_idf_dict in tf_idf.get_tf_idf_dict().items():\n",
    "    print doc \n",
    "    print tf_idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 4 6] <type 'numpy.ndarray'>\n",
      "[[0 1 2]\n",
      " [2 4 6]] <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr1 = np.array([1, 3, 4, 6])\n",
    "arr2 = np.array([[0, 1, 2], [2, 4, 6]])\n",
    "\n",
    "print arr1, type(arr1)\n",
    "print arr2, type(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]\n",
      "\n",
      "\n",
      "  [[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]\n",
      "\n",
      "\n",
      "  [[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]\n",
      "\n",
      "\n",
      "  [[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]\n",
      "\n",
      "\n",
      "  [[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]\n",
      "\n",
      "\n",
      "  [[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]\n",
      "\n",
      "\n",
      "  [[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "   [[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    ..., \n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "    [ 1.  1.  1. ...,  1.  1.  1.]]]]]\n"
     ]
    }
   ],
   "source": [
    "print np.ones((3, 3, 2, 7, 8))\n",
    "#print np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
